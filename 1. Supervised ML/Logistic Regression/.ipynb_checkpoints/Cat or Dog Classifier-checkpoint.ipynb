{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing and data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator,load_img,img_to_array,array_to_img\n",
    "from keras.applications.xception import Xception,preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen=ImageDataGenerator(rotation_range=40,\n",
    "                          width_shift_range=0.2,\n",
    "                          height_shift_range=0.2,\n",
    "                          shear_range=0.2,\n",
    "                          zoom_range=0.2,\n",
    "                          horizontal_flip=True,\n",
    "                          fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=load_img(\"cat.2.jpg\")\n",
    "img=img_to_array(img)\n",
    "img=np.expand_dims(img,axis=0)\n",
    "img=preprocess_input(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i=0\n",
    "for batch in datagen.flow(img,batch_size=1,save_to_dir='preview',save_prefix='cat',save_format='jpeg'):\n",
    "    i+=1\n",
    "    if i>20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(im):\n",
    "    im=img_to_array(im)\n",
    "    im=np.expand_dims(im,axis=0)\n",
    "    im=preprocess_input(im)\n",
    "    return im[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project starts from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=r\"E:\\003 IBM CE\\3. Artificial Intelligence\\Mody\\Cat vs Dog Classification DL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(data_dir,\"train\",'cats')) #reading out training images for cat.\n",
    "cat_train_img_names=glob.glob(\"*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train=[] #processing these images and storing them into a list.\n",
    "for i in cat_train_img_names:\n",
    "    im=load_img(i,target_size=(224,224,3))\n",
    "    cat_train.append(preprocess(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(data_dir,\"train\",'dogs'))\n",
    "dogs_train_img_names=glob.glob(\"*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_train=[]\n",
    "for i in dogs_train_img_names:\n",
    "    im=load_img(i,target_size=(224,224,3))\n",
    "    dog_train.append(preprocess(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(data_dir,\"test\",'cat'))\n",
    "cat_test_img_names=glob.glob(\"*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_test=[]\n",
    "for i in cat_test_img_names:\n",
    "    im=load_img(i,target_size=(224,224,3))\n",
    "    cat_test.append(preprocess(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(data_dir,\"test\",'dog'))\n",
    "dog_test_img_names=glob.glob(\"*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_test=[]\n",
    "for i in dog_test_img_names:\n",
    "    im=load_img(i,target_size=(224,224,3))\n",
    "    dog_test.append(preprocess(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_test=np.array(cat_test,dtype='float32') #converting images into array.\n",
    "cat_train=np.array(cat_train,dtype='float32')\n",
    "dog_test=np.array(dog_test,dtype='float32')\n",
    "dog_train=np.array(dog_train,dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400, 224, 224, 3),\n",
       " (1000, 224, 224, 3),\n",
       " (400, 224, 224, 3),\n",
       " (1000, 224, 224, 3))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_test.shape,cat_train.shape,dog_test.shape,dog_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=np.concatenate((cat_train,dog_train),axis=0) #concatenating training and testing images.\n",
    "test=np.concatenate((cat_test,dog_test),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 224, 224, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 224, 224, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=[0]*cat_train.shape[0]+[1]*dog_train.shape[0] #labelling training and testing images in order to create the target variable.\n",
    "y_test=[0]*cat_test.shape[0]+[1]*dog_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.array(y_train,dtype='float32') #converting these target variable into a array form.\n",
    "y_test=np.array(y_test,dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model=Xception(include_top=False,pooling='avg',input_shape=(224,224,3)) \n",
    "train_features=base_model.predict(train) #extracting the features by pretrained model and stacking a logistic layer as the output layer in order to do the binary classification as we hav only two classes (cat and dog)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.150080</td>\n",
       "      <td>0.811858</td>\n",
       "      <td>0.342450</td>\n",
       "      <td>0.006123</td>\n",
       "      <td>0.148101</td>\n",
       "      <td>0.430158</td>\n",
       "      <td>0.007205</td>\n",
       "      <td>1.474634</td>\n",
       "      <td>0.701332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119137</td>\n",
       "      <td>0.061524</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.169260</td>\n",
       "      <td>0.120772</td>\n",
       "      <td>0.825829</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.157766</td>\n",
       "      <td>1.569686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.077801</td>\n",
       "      <td>0.128635</td>\n",
       "      <td>0.053697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207505</td>\n",
       "      <td>0.068977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009002</td>\n",
       "      <td>0.002372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.012005</td>\n",
       "      <td>0.563872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.253329</td>\n",
       "      <td>0.014175</td>\n",
       "      <td>0.773287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013031</td>\n",
       "      <td>0.225522</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.629110</td>\n",
       "      <td>0.020101</td>\n",
       "      <td>0.033078</td>\n",
       "      <td>1.071828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.441684</td>\n",
       "      <td>0.098145</td>\n",
       "      <td>0.706996</td>\n",
       "      <td>0.514371</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.561485</td>\n",
       "      <td>0.007586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.653861</td>\n",
       "      <td>0.330843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144847</td>\n",
       "      <td>1.024179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.717531</td>\n",
       "      <td>0.701420</td>\n",
       "      <td>0.667020</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.430907</td>\n",
       "      <td>0.778511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.591277</td>\n",
       "      <td>0.421175</td>\n",
       "      <td>0.571200</td>\n",
       "      <td>0.626708</td>\n",
       "      <td>0.749512</td>\n",
       "      <td>0.927735</td>\n",
       "      <td>0.113868</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.012677</td>\n",
       "      <td>0.207897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.486649</td>\n",
       "      <td>0.006397</td>\n",
       "      <td>0.493272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.177995</td>\n",
       "      <td>0.120101</td>\n",
       "      <td>0.186987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.817334</td>\n",
       "      <td>0.973186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130042</td>\n",
       "      <td>0.304204</td>\n",
       "      <td>0.086013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078088</td>\n",
       "      <td>0.770991</td>\n",
       "      <td>0.132231</td>\n",
       "      <td>1.532350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008081</td>\n",
       "      <td>0.307886</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.009148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018864</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.039513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.180184</td>\n",
       "      <td>0.227867</td>\n",
       "      <td>0.016785</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.005835</td>\n",
       "      <td>0.033974</td>\n",
       "      <td>0.597758</td>\n",
       "      <td>0.339649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087334</td>\n",
       "      <td>0.008494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107313</td>\n",
       "      <td>0.213265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290743</td>\n",
       "      <td>0.318834</td>\n",
       "      <td>0.613553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.055679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044460</td>\n",
       "      <td>0.344969</td>\n",
       "      <td>0.006694</td>\n",
       "      <td>0.320004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.152697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.713272</td>\n",
       "      <td>0.231147</td>\n",
       "      <td>0.058665</td>\n",
       "      <td>0.586854</td>\n",
       "      <td>0.172884</td>\n",
       "      <td>0.039588</td>\n",
       "      <td>0.003617</td>\n",
       "      <td>0.084551</td>\n",
       "      <td>0.060280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.012894</td>\n",
       "      <td>0.473242</td>\n",
       "      <td>0.125561</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.821533</td>\n",
       "      <td>0.225250</td>\n",
       "      <td>1.106480</td>\n",
       "      <td>0.335779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026384</td>\n",
       "      <td>0.075430</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.561156</td>\n",
       "      <td>0.002739</td>\n",
       "      <td>0.136715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.001302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.025552</td>\n",
       "      <td>0.029997</td>\n",
       "      <td>0.363014</td>\n",
       "      <td>0.403041</td>\n",
       "      <td>0.185265</td>\n",
       "      <td>0.301670</td>\n",
       "      <td>0.029663</td>\n",
       "      <td>0.256702</td>\n",
       "      <td>0.069659</td>\n",
       "      <td>0.488135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202354</td>\n",
       "      <td>0.073466</td>\n",
       "      <td>0.127261</td>\n",
       "      <td>0.215801</td>\n",
       "      <td>0.158030</td>\n",
       "      <td>0.027694</td>\n",
       "      <td>0.487767</td>\n",
       "      <td>0.246017</td>\n",
       "      <td>0.544762</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2048 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6     \\\n",
       "0     0.150080  0.811858  0.342450  0.006123  0.148101  0.430158  0.007205   \n",
       "1     0.077801  0.128635  0.053697  0.000000  0.207505  0.068977  0.000000   \n",
       "2     0.253329  0.014175  0.773287  0.000000  0.013031  0.225522  0.000000   \n",
       "3     0.441684  0.098145  0.706996  0.514371  0.000649  0.561485  0.007586   \n",
       "4     0.591277  0.421175  0.571200  0.626708  0.749512  0.927735  0.113868   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1995  0.000000  0.130042  0.304204  0.086013  0.000000  0.000000  0.078088   \n",
       "1996  0.039513  0.000000  0.180184  0.227867  0.016785  0.005885  0.005835   \n",
       "1997  0.055679  0.000000  0.000000  0.044460  0.344969  0.006694  0.320004   \n",
       "1998  0.012894  0.473242  0.125561  0.000000  0.038456  0.000000  0.821533   \n",
       "1999  0.025552  0.029997  0.363014  0.403041  0.185265  0.301670  0.029663   \n",
       "\n",
       "          7         8         9     ...      2038      2039      2040  \\\n",
       "0     1.474634  0.701332  0.000000  ...  0.119137  0.061524  0.061700   \n",
       "1     0.009002  0.002372  0.000000  ...  0.000000  0.325826  0.000000   \n",
       "2     0.338383  0.000000  0.010185  ...  0.207356  0.000000  0.159052   \n",
       "3     0.000000  0.653861  0.330843  ...  0.000000  0.144847  1.024179   \n",
       "4     0.000723  0.012677  0.207897  ...  0.486649  0.006397  0.493272   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1995  0.770991  0.132231  1.532350  ...  0.000000  0.008109  0.000000   \n",
       "1996  0.033974  0.597758  0.339649  ...  0.087334  0.008494  0.000000   \n",
       "1997  0.000000  0.000000  0.152697  ...  0.000000  0.713272  0.231147   \n",
       "1998  0.225250  1.106480  0.335779  ...  0.026384  0.075430  0.000000   \n",
       "1999  0.256702  0.069659  0.488135  ...  0.202354  0.073466  0.127261   \n",
       "\n",
       "          2041      2042      2043      2044      2045      2046      2047  \n",
       "0     0.169260  0.120772  0.825829  0.000829  0.000902  0.157766  1.569686  \n",
       "1     0.000902  0.012005  0.563872  0.000000  0.000000  0.000000  0.153744  \n",
       "2     0.000000  0.046788  0.000000  0.629110  0.020101  0.033078  1.071828  \n",
       "3     0.000000  0.717531  0.701420  0.667020  0.000023  0.430907  0.778511  \n",
       "4     0.000000  0.177995  0.120101  0.186987  0.000000  0.817334  0.973186  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1995  0.008081  0.307886  0.000363  0.009148  0.000000  0.018864  0.000000  \n",
       "1996  0.107313  0.213265  0.000000  0.000000  0.290743  0.318834  0.613553  \n",
       "1997  0.058665  0.586854  0.172884  0.039588  0.003617  0.084551  0.060280  \n",
       "1998  0.000000  0.561156  0.002739  0.136715  0.000000  0.000698  0.001302  \n",
       "1999  0.215801  0.158030  0.027694  0.487767  0.246017  0.544762  0.000000  \n",
       "\n",
       "[2000 rows x 2048 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2048)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf=LogisticRegression() #creating the instance of logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_features,y_train) #fitting the extracted trainned features and target variable into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features=base_model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 2048)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.985"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds==y_test).sum()/y_test.shape[0] #model accuracy 98.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
